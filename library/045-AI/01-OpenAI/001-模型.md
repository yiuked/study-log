## 一、关键词
### 1、Tokens
与API进行交互时会消耗一定数量的tokens，消耗的tokens数量取决于输入、输出的文本字符数，对于英语文本，1个token大约是4个字符或0.75个单词。如莎士比亚的作品集大约有90万个单词或120万个标记，可以参考[分词工具](https://platform.openai.com/tokenizer)。 100 个tokens 将花费 $0.002

## 二、模型
### 1、GPT-3
GPT-3 可以理解和生成自然语言，它包含以下四种模型
- text-davinci-003 
> 最有能力的GPT-3模型。可以完成其他模型所能完成的任何任务，最大支持4000个tokens
- text-curie-001 
>能力很强，但比Davinci更快，成本更低，最大支持2048个tokens。
- text-babbage-001 
>能够完成简单的任务，速度非常快，而且成本较低，最大支持2048个tokens。
- text-ada-001 
>能够完成非常简单的任务，通常是GPT-3系列中最快的型号，而且成本最低，最大支持4000个tokens。

### 2、Codex
Codex模型是GPT-3模型的后代，可以理解和生成代码。训练数据包含自然语言和来自GitHub的数十亿行公共代码。在Python中的能力最强，精通十几种语言，包括JavaScript、Go、Perl、PHP、Ruby、Swift、TypeScript、SQL，甚至Shell。
- code-davinci-002
> 最有能力的Codex模型。特别擅长于将自然语言翻译成代码。除了完成代码外，还支持在代码内插入补全内容，最大支持8000个tokens。
- code-cushman-001
>几乎和Davinci Codex的能力一样，但速度稍快。这种速度优势可能使它更适合于实时应用，最大支持2048个tokens。
